{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b367dba2",
   "metadata": {},
   "source": [
    "### Atoki Bolutife\n",
    "bolutife.atoki@estudiante.uam.es\n",
    "### People Detection Lab02 using Yolov4-tiny on Opencv and python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50962690",
   "metadata": {},
   "source": [
    "##### Overview of Algorithm:\n",
    "The People Detection Algorithm utilizes a stripped down version the You Only Look Once (YOLO) model i.e YOLOv4-tiny as the object detection model (in this case people detection), it was created by Joseph Redmond and it acheives Real-time object detection. The Algorithm runs on the python programming language and uses functions and methods from OpenCv and imutils libraries and is applied on a video sequence of people walking by in a university (common and busy area), so there are occlusions and overlapping people in the frames. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0814ff",
   "metadata": {},
   "source": [
    "##### Model Evaluation:\n",
    "1. The model used is the fourth version of the YOLO series\n",
    "2. The YOLO machine learning models applies a single neural network to the image by, splitting the image into regions and calculating the probabilities for each region, as opposed to some other models that implement localizers and classifiers at multiple scales and locations on the image. \n",
    "3. YOLOv4-tiny is a \"lite\" or stripped down version of the Original version 4, for acheiving real-time processing (avg 9fps) by prioritizing Speed over Accuracy, while still providing accurate results which can further be influenced via threshold values\n",
    "4. It retains global context since the image is viewed at once (as a whole)\n",
    "5. The model being implemented (the YOLOv4-tiny) is 8 times faster than the original YOLOv4, requiring less computation time and achieving better real-time processing due to the fact that it makes use of 29 pre-trained convolutional layers as opposed to 129 pre-trained layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc36f19",
   "metadata": {},
   "source": [
    "Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba71f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad1550",
   "metadata": {},
   "source": [
    "Threshold values that can be adjusted for better performance if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "863c7b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "NMS_THRESHOLD=0.0 #Non-maximum suppression threshold for separating overlapping detections\n",
    "#original was 0.3\n",
    "MIN_CONFIDENCE=0.2 #Confidence score for detections\n",
    "#original was 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa52f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pedestrian_detection(image, model, layer_name, personidz=0):\n",
    "    (H, W) = image.shape[:2] #To obtain the rows and columns of the image\n",
    "    results = [] #Empty list to store tuples having prediction confidence, bounding box coordinates, and centroid for each detection\n",
    "\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),\n",
    "        swapRB=True, crop=False) #Performing Image pre-processing; mean subtraction, scaling and channel swapping\n",
    "    cv2.imshow(\"Processed\", image)\n",
    "    \n",
    "    \n",
    "    model.setInput(blob)\n",
    "    layerOutputs = model.forward(layer_name)\n",
    "\n",
    "    boxes = []\n",
    "    centroids = []\n",
    "    confidences = []\n",
    "\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            if classID == personidz and confidence > MIN_CONFIDENCE:\n",
    "\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                centroids.append((centerX, centerY))\n",
    "                confidences.append(float(confidence))\n",
    "    # apply non-maxima suppression to suppress weak, overlapping\n",
    "    # bounding boxes\n",
    "    idzs = cv2.dnn.NMSBoxes(boxes, confidences, MIN_CONFIDENCE, NMS_THRESHOLD)\n",
    "    # ensure at least one detection exists\n",
    "    if len(idzs) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in idzs.flatten():\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            # update our results list to consist of the person\n",
    "            # prediction probability, bounding box coordinates,\n",
    "            # and the centroid\n",
    "            res = (confidences[i], (x, y, x + w, y + h), centroids[i])\n",
    "            results.append(res)\n",
    "    # return the list of results\n",
    "    return [results, confidences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f2d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "img_array = []\n",
    "# for filename in glob.glob('Videos/tud-campus-sequence/*.png'):\n",
    "for filename in glob.glob('Documents/UAM/PDBR/dataset/*.jpg'):\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter('video.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08128207",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsPath = \"coco.names\"\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "\n",
    "weights_path = \"yolov4-tiny.weights\"\n",
    "config_path = \"yolov4-tiny.cfg\"\n",
    "\n",
    "model = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "'''\n",
    "model.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "model.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "'''\n",
    "\n",
    "layer_name = model.getLayerNames()\n",
    "layer_name = [layer_name[i - 1] for i in model.getUnconnectedOutLayers()]\n",
    "cap = cv2.VideoCapture(\"video.avi\")\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe713915",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_frame_time = 0\n",
    "  \n",
    "# used to record the time at which we processed current frame\n",
    "new_frame_time = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    (grabbed, image) = cap.read()\n",
    "\n",
    "    if not grabbed:\n",
    "        break\n",
    "    image = imutils.resize(image, width=700)\n",
    "    \n",
    "    [results, confidences] = pedestrian_detection(image, model, layer_name,\n",
    "        personidz=LABELS.index(\"person\")) #Function Call\n",
    "\n",
    "    for res in results:\n",
    "        cv2.rectangle(image, (res[1][0],res[1][1]), (res[1][2],res[1][3]), (0, 255, 0), 2)\n",
    "\n",
    "        \n",
    "#This bit calculates the fps and displayes on each frame        \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        # time when we finish processing for this frame\n",
    "    new_frame_time = time.time()\n",
    "\n",
    "    # Calculating the fps\n",
    "    # fps will be number of frame processed in given time frame\n",
    "    # since their will be most of time error of 0.001 second\n",
    "    # we will be subtracting it to get more accurate result\n",
    "    fps = 1/(new_frame_time-prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    "\n",
    "    # converting the fps into integer\n",
    "    fps = int(fps)\n",
    "\n",
    "    # converting the fps to string so that we can display it on frame\n",
    "    # by using putText function\n",
    "    fps = str(fps)\n",
    "\n",
    "    # putting the FPS count on the frame\n",
    "    cv2.putText(image, fps, (7, 70), font, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "        \n",
    "    cv2.imshow(\"Detection\",image)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643c7544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8510034680366516, 0.3837650418281555, 0.2269079089164734]\n"
     ]
    }
   ],
   "source": [
    "print(confidences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f81981",
   "metadata": {},
   "source": [
    "## References\n",
    "1. \"Real-time Pedestrian Detection using Python & OpenCV\", Data-Flair, 2023 [Online]. Available: https://data-flair.training/blogs/pedestrian-detection-python-opencv/\n",
    "2. \"Creating video from images using OpenCv and python\", TheAILearner, 2023 [Online]. Available: https://theailearner.com/2018/10/15/creating-video-from-images-using-opencv-python/\n",
    "3. \"Deep learning: How OpenCV’s blobFromImage works\", pyimagesearch, 2017 [Online]. Available: https://pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/\n",
    "4. \"Python – Displaying real time FPS at which webcam/video file is processed using OpenCV\", pyimagesearch, 2023 [Online]. Available: https://www.geeksforgeeks.org/python-displaying-real-time-fps-at-which-webcam-video-file-is-processed-using-opencv/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
