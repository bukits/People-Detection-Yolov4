{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc36f19",
   "metadata": {},
   "source": [
    "Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba71f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad1550",
   "metadata": {},
   "source": [
    "Threshold values that can be adjusted for better performance if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "863c7b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "NMS_THRESHOLD=0.0 #Non-maximum suppression threshold for separating overlapping detections\n",
    "#original was 0.3\n",
    "MIN_CONFIDENCE=0.2 #Confidence score for detections\n",
    "#original was 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa52f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pedestrian_detection(image, model, layer_name, personidz=0):\n",
    "    (H, W) = image.shape[:2] #To obtain the rows and columns of the image\n",
    "    results = [] #Empty list to store tuples having prediction confidence, bounding box coordinates, and centroid for each detection\n",
    "\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),\n",
    "        swapRB=True, crop=False) #Performing Image pre-processing; mean subtraction, scaling and channel swapping\n",
    "    cv2.imshow(\"Processed\", image)\n",
    "    \n",
    "    \n",
    "    model.setInput(blob)\n",
    "    layerOutputs = model.forward(layer_name)\n",
    "\n",
    "    boxes = []\n",
    "    centroids = []\n",
    "    confidences = []\n",
    "\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            if classID == personidz and confidence > MIN_CONFIDENCE:\n",
    "\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                centroids.append((centerX, centerY))\n",
    "                confidences.append(float(confidence))\n",
    "    # apply non-maxima suppression to suppress weak, overlapping\n",
    "    # bounding boxes\n",
    "    idzs = cv2.dnn.NMSBoxes(boxes, confidences, MIN_CONFIDENCE, NMS_THRESHOLD)\n",
    "    # ensure at least one detection exists\n",
    "    if len(idzs) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in idzs.flatten():\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            # update our results list to consist of the person\n",
    "            # prediction probability, bounding box coordinates,\n",
    "            # and the centroid\n",
    "#             if ((w in range(20,25)) and (h in range(40,50))):\n",
    "#                 continue\n",
    "                \n",
    "            #if (math.sqrt((w**2) + (h**2)) <= 80):\n",
    "             #   continue\n",
    "            res = (confidences[i], (x, y, x + w, y + h), centroids[i])\n",
    "            results.append(res)\n",
    "    # return the list of results\n",
    "    return [results, confidences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f2d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "img_array = []\n",
    "test_set = 'badminton'\n",
    "root = 'C:/Users/tbukits/Documents/UAM/PDBR/dataset/' + test_set\n",
    "\n",
    "dataIn = open(root + '/dataIn.txt', 'r')\n",
    "\n",
    "data  = dataIn.read()\n",
    "\n",
    "frame_ids = data.split('\\n')\n",
    "\n",
    "path = root + '/*.jpg'\n",
    "\n",
    "for filename in glob.glob(path):\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter('video.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08128207",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsPath = \"coco.names\"\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "\n",
    "weights_path = \"yolov4-tiny.weights\"\n",
    "config_path = \"yolov4-tiny.cfg\"\n",
    "\n",
    "model = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "'''\n",
    "model.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "model.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "'''\n",
    "\n",
    "layer_name = model.getLayerNames()\n",
    "layer_name = [layer_name[i - 1] for i in model.getUnconnectedOutLayers()]\n",
    "cap = cv2.VideoCapture(\"video.avi\")\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56467110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_output_file(frame_id, bounding_boxes, scores):\n",
    "    if len(bounding_boxes) == 0:\n",
    "        row = '\"./Videos/' + frame_id + '\";\\n'\n",
    "    else:\n",
    "        row = '\"./Videos/' + frame_id + '\"; '\n",
    "    index = 0\n",
    "    for box in bounding_boxes:\n",
    "        score = scores[index]\n",
    "        top_left_x = box[1][0]\n",
    "        top_left_y = box[1][1]\n",
    "        width = box[1][2] - top_left_x\n",
    "        height = box[1][3] - top_left_y\n",
    "        if len(bounding_boxes) == 1:\n",
    "            row += '(' + str(top_left_x) + ', ' + str(top_left_y) + ', ' + str(width) + ', ' + str(height) + '):' + str(score) + ';\\n'\n",
    "        elif index == 0:\n",
    "            row += '(' + str(top_left_x) + ', ' + str(top_left_y) + ', ' + str(width) + ', ' + str(height) + '):' + str(score) + ', '\n",
    "        elif index < len(bounding_boxes) - 1:\n",
    "            row += '(' + str(top_left_x) + ', ' + str(top_left_y) + ', ' + str(width) + ', ' + str(height) + '):' + str(score) + ', '\n",
    "        else:\n",
    "            row += '(' + str(top_left_x) + ', ' + str(top_left_y) + ', ' + str(width) + ', ' + str(height) + '):' + str(score) + ';\\n'\n",
    "        index += 1\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a38eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "def backgroundSubstractor(frame):\n",
    "    fgmask = fgbg.apply(frame)    \n",
    "    masked_img = cv2.bitwise_and(frame, frame, mask = fgmask)\n",
    "    return masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe713915",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_frame_time = 0\n",
    "  \n",
    "# used to record the time at which we processed current frame\n",
    "new_frame_time = 0\n",
    "\n",
    "file = open(test_set + '.idl', \"w\")\n",
    "\n",
    "counter = 0\n",
    "while True:\n",
    "    (grabbed, image) = cap.read()\n",
    "\n",
    "    if not grabbed:\n",
    "        break\n",
    "    #image = imutils.resize(image, width=700)\n",
    "    \n",
    "    image = backgroundSubstractor(image)\n",
    "    \n",
    "    [results, confidences] = pedestrian_detection(image, model, layer_name,\n",
    "        personidz=LABELS.index(\"person\")) #Function Call\n",
    "    frame_id = frame_ids[counter]\n",
    "    row = make_output_file(frame_id, results, confidences)\n",
    "    file.write(row)\n",
    "\n",
    "    \n",
    "    for res in results:\n",
    "        cv2.rectangle(image, (res[1][0],res[1][1]), (res[1][2],res[1][3]), (0, 255, 0), 2)\n",
    "    counter += 1\n",
    "        \n",
    "#This bit calculates the fps and displayes on each frame        \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        # time when we finish processing for this frame\n",
    "    new_frame_time = time.time()\n",
    "\n",
    "    # Calculating the fps\n",
    "    # fps will be number of frame processed in given time frame\n",
    "    # since their will be most of time error of 0.001 second\n",
    "    # we will be subtracting it to get more accurate result\n",
    "    fps = 1/(new_frame_time-prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    "\n",
    "    # converting the fps into integer\n",
    "    fps = int(fps)\n",
    "\n",
    "    # converting the fps to string so that we can display it on frame\n",
    "    # by using putText function\n",
    "    fps = str(fps)\n",
    "\n",
    "    # putting the FPS count on the frame\n",
    "    cv2.putText(image, fps, (7, 70), font, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "        \n",
    "    cv2.imshow(\"Detection\",image)\n",
    "    \n",
    "    cv2.imwrite(\"processed/\"+str(counter)+\".jpg\", image)\n",
    "    \n",
    "#     cv2.imwrite('lena_opencv_red.jpg', image)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c283f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "img_array = []\n",
    "# for filename in glob.glob('Videos/tud-campus-sequence/*.png'):\n",
    "for filename in glob.glob('processed/*.jpg'):\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter('backdoor.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "\n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "643c7544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(confidences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f81981",
   "metadata": {},
   "source": [
    "## References\n",
    "1. \"Real-time Pedestrian Detection using Python & OpenCV\", Data-Flair, 2023 [Online]. Available: https://data-flair.training/blogs/pedestrian-detection-python-opencv/\n",
    "2. \"Creating video from images using OpenCv and python\", TheAILearner, 2023 [Online]. Available: https://theailearner.com/2018/10/15/creating-video-from-images-using-opencv-python/\n",
    "3. \"Deep learning: How OpenCV’s blobFromImage works\", pyimagesearch, 2017 [Online]. Available: https://pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/\n",
    "4. \"Python – Displaying real time FPS at which webcam/video file is processed using OpenCV\", pyimagesearch, 2023 [Online]. Available: https://www.geeksforgeeks.org/python-displaying-real-time-fps-at-which-webcam-video-file-is-processed-using-opencv/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
